{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce RTX 3090\n",
      "Total Memory:  23.7 GB\n",
      "Memory Usage:\n",
      "Allocated: 0.3 GB\n",
      "Cached:    2.2 GB\n"
     ]
    }
   ],
   "source": [
    "# Memoria GPU\n",
    "import torch\n",
    "print(torch.cuda.get_device_name(0))\n",
    "print(\"Total Memory: \",round(torch.cuda.mem_get_info(0)[1]/1024**3,1),'GB')\n",
    "print('Memory Usage:')\n",
    "# x = torch.rand(100,3,512,512).cuda() # simulacion de 100 imagenes de 512x512 a color...\n",
    "print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')\n",
    "\n",
    "# algo raro, Nvidia dice que hay 24 GB, en la industria se acostumbra a que GB es potencias de 10 y GiB es potencias de 1024**3 en byes.\n",
    "# pero aca usaron los GB como GiB, por lo que se tienen 24576 MiB. \n",
    "# se scan las cuentas como si fueran 24000 igualmente.\n",
    "mem_rtx_3090 = 24000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determinar de forma general un batch size apropiado para nuestro modelo.\n",
    "\n",
    "https://discuss.pytorch.org/t/how-to-determine-the-largest-batch-size-of-a-given-model-saturating-the-gpu/146075\n",
    "\n",
    "Aplicando una busqueda binaria con la funcion de Suraj.\n",
    "\n",
    "En principio siempre se quiere conseguir el tamaño maximo de batch size que soporte el hardware.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "\n",
    "dimension_imagen = [3,32,32]\n",
    "\n",
    "def proc_time(b_sz, model, n_iter=10):\n",
    "    x = torch.rand(b_sz, *dimension_imagen).cuda()\n",
    "    model.cuda()\n",
    "    torch.cuda.synchronize()\n",
    "    start = time.time()\n",
    "    for _ in range(n_iter):\n",
    "        model(x)\n",
    "        print(torch.cuda.mem_get_info())\n",
    "        print(os.popen(\"nvidia-smi\").read())\n",
    "        \n",
    "    torch.cuda.synchronize()\n",
    "    end = time.time() - start\n",
    "    throughput = b_sz * n_iter / end\n",
    "    print(f\"Batch: {b_sz} \\t {throughput} samples/sec\")\n",
    "    return (b_sz, throughput, )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/46654424/how-to-calculate-optimal-batch-size \n",
    "\n",
    "Use the summaries provided by pytorchsummary (pip install) or keras (builtin).\n",
    "\n",
    "E.g.\n",
    "\n",
    "from torchsummary import summary\n",
    "summary(model)\n",
    ".....\n",
    ".....\n",
    "================================================================\n",
    "Total params: 1,127,495\n",
    "Trainable params: 1,127,495\n",
    "Non-trainable params: 0\n",
    "----------------------------------------------------------------\n",
    "Input size (MB): 0.02\n",
    "Forward/backward pass size (MB): 13.93\n",
    "Params size (MB): 4.30\n",
    "Estimated Total Size (MB): 18.25\n",
    "----------------------------------------------------------------\n",
    "Each instance you put in the batch will require a full forward/backward pass in memory, your model you only need once. People seem to prefer batch sizes of powers of two, probably because of automatic layout optimization on the gpu.\n",
    "\n",
    "Don't forget to linearly increase your learning rate when increasing the batch size.\n",
    "\n",
    "Let's assume we have a Tesla P100 at hand with 16 GB memory.\n",
    "\n",
    "(16000 - model_size) / (forward_back_ward_size)\n",
    "(16000 - 4.3) / 18.25 = 1148.29\n",
    "rounded to powers of 2 results in batch size 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "Sequential                               [10, 64, 28, 28]          --\n",
      "├─Conv2d: 1-1                            [10, 20, 30, 30]          560\n",
      "├─ReLU: 1-2                              [10, 20, 30, 30]          --\n",
      "├─Conv2d: 1-3                            [10, 64, 28, 28]          11,584\n",
      "├─ReLU: 1-4                              [10, 64, 28, 28]          --\n",
      "==========================================================================================\n",
      "Total params: 12,144\n",
      "Trainable params: 12,144\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 95.86\n",
      "==========================================================================================\n",
      "Input size (MB): 0.12\n",
      "Forward/backward pass size (MB): 5.45\n",
      "Params size (MB): 0.05\n",
      "Estimated Total Size (MB): 5.63\n",
      "==========================================================================================\n",
      "model_size 0.05\n",
      "forward_back_ward_size 5.63\n",
      "maximum possible batch size: 4263\n"
     ]
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "import torch.nn as nn\n",
    "\n",
    "model = nn.Sequential(\n",
    "          nn.Conv2d(3,20,3),\n",
    "          nn.ReLU(),\n",
    "          nn.Conv2d(20,64,3),\n",
    "          nn.ReLU()\n",
    "        )\n",
    "batch_size = 10\n",
    "resumen = summary(model, input_size=(batch_size, *dimension_imagen))\n",
    "print(resumen)\n",
    "\n",
    "import re\n",
    "model_size = re.search(r\"Params size \\(MB\\): (\\d*\\.?\\d*)\",resumen.__repr__()).group(1)\n",
    "forward_back_ward_size = re.search(r\"Estimated Total Size \\(MB\\): (\\d*\\.?\\d*)\",resumen.__repr__()).group(1)\n",
    "print(\"model_size\",model_size)\n",
    "print(\"forward_back_ward_size\",forward_back_ward_size)\n",
    "max_batch_size = (mem_rtx_3090 - float(model_size)) / float(forward_back_ward_size)\n",
    "print(\"maximum possible batch size:\",round(max_batch_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "Sequential                               [42630, 64, 28, 28]       --\n",
      "├─Conv2d: 1-1                            [42630, 20, 30, 30]       560\n",
      "├─ReLU: 1-2                              [42630, 20, 30, 30]       --\n",
      "├─Conv2d: 1-3                            [42630, 64, 28, 28]       11,584\n",
      "├─ReLU: 1-4                              [42630, 64, 28, 28]       --\n",
      "==========================================================================================\n",
      "Total params: 12,144\n",
      "Trainable params: 12,144\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (G): 408.65\n",
      "==========================================================================================\n",
      "Input size (MB): 523.84\n",
      "Forward/backward pass size (MB): 23250.74\n",
      "Params size (MB): 0.05\n",
      "Estimated Total Size (MB): 23774.63\n",
      "==========================================================================================\n",
      "model_size 0.05\n",
      "forward_back_ward_size 23774.63\n",
      "maximum possible batch size: 1\n"
     ]
    }
   ],
   "source": [
    "# revisamos la estimacion con el valor maximo obtenido de la cuenta anterior.\n",
    "max_batch_size_recommended = 4263\n",
    "max_batch_size_recommended = 42630\n",
    "\n",
    "\n",
    "resumen = summary(model, input_size=(max_batch_size_recommended, *dimension_imagen))\n",
    "print(resumen)\n",
    "\n",
    "import re\n",
    "model_size = re.search(r\"Params size \\(MB\\): (\\d*\\.?\\d*)\",resumen.__repr__()).group(1)\n",
    "forward_back_ward_size = re.search(r\"Estimated Total Size \\(MB\\): (\\d*\\.?\\d*)\",resumen.__repr__()).group(1)\n",
    "print(\"model_size\",model_size)\n",
    "print(\"forward_back_ward_size\",forward_back_ward_size)\n",
    "max_batch_size = (mem_rtx_3090 - float(model_size)) / float(forward_back_ward_size)\n",
    "print(\"maximum possible batch size:\",round(max_batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19564134400, 25423577088)\n",
      "Sat Oct 15 23:21:44 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 515.65.01    Driver Version: 515.65.01    CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0  On |                  N/A |\n",
      "|  0%   52C    P2    45W / 350W |   5588MiB / 24576MiB |      1%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      2322      G   /usr/lib/xorg/Xorg                276MiB |\n",
      "|    0   N/A  N/A      2685      G   /usr/bin/gnome-shell               62MiB |\n",
      "|    0   N/A  N/A      3609      G   ...703281151127485480,131072      317MiB |\n",
      "|    0   N/A  N/A     33146      G   ...RendererForSitePerProcess      202MiB |\n",
      "|    0   N/A  N/A     33874      C   ...da3/envs/tesis/bin/python     4695MiB |\n",
      "+-----------------------------------------------------------------------------+\n",
      "\n",
      "(19564134400, 25423577088)\n",
      "Sat Oct 15 23:21:44 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 515.65.01    Driver Version: 515.65.01    CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0  On |                  N/A |\n",
      "|  0%   53C    P2    45W / 350W |   5588MiB / 24576MiB |     24%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      2322      G   /usr/lib/xorg/Xorg                276MiB |\n",
      "|    0   N/A  N/A      2685      G   /usr/bin/gnome-shell               62MiB |\n",
      "|    0   N/A  N/A      3609      G   ...703281151127485480,131072      317MiB |\n",
      "|    0   N/A  N/A     33146      G   ...RendererForSitePerProcess      202MiB |\n",
      "|    0   N/A  N/A     33874      C   ...da3/envs/tesis/bin/python     4695MiB |\n",
      "+-----------------------------------------------------------------------------+\n",
      "\n",
      "(19564134400, 25423577088)\n",
      "Sat Oct 15 23:21:44 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 515.65.01    Driver Version: 515.65.01    CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0  On |                  N/A |\n",
      "|  0%   53C    P2    56W / 350W |   5588MiB / 24576MiB |     24%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      2322      G   /usr/lib/xorg/Xorg                276MiB |\n",
      "|    0   N/A  N/A      2685      G   /usr/bin/gnome-shell               62MiB |\n",
      "|    0   N/A  N/A      3609      G   ...703281151127485480,131072      317MiB |\n",
      "|    0   N/A  N/A     33146      G   ...RendererForSitePerProcess      202MiB |\n",
      "|    0   N/A  N/A     33874      C   ...da3/envs/tesis/bin/python     4695MiB |\n",
      "+-----------------------------------------------------------------------------+\n",
      "\n",
      "(19564068864, 25423577088)\n",
      "Sat Oct 15 23:21:44 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 515.65.01    Driver Version: 515.65.01    CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0  On |                  N/A |\n",
      "|  0%   54C    P2    69W / 350W |   5594MiB / 24576MiB |     20%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      2322      G   /usr/lib/xorg/Xorg                276MiB |\n",
      "|    0   N/A  N/A      2685      G   /usr/bin/gnome-shell               62MiB |\n",
      "|    0   N/A  N/A      3609      G   ...703281151127485480,131072      317MiB |\n",
      "|    0   N/A  N/A     33146      G   ...RendererForSitePerProcess      208MiB |\n",
      "|    0   N/A  N/A     33874      C   ...da3/envs/tesis/bin/python     4695MiB |\n",
      "+-----------------------------------------------------------------------------+\n",
      "\n",
      "(19557777408, 25423577088)\n",
      "Sat Oct 15 23:21:44 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 515.65.01    Driver Version: 515.65.01    CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0  On |                  N/A |\n",
      "|  0%   54C    P2    79W / 350W |   5594MiB / 24576MiB |     20%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      2322      G   /usr/lib/xorg/Xorg                276MiB |\n",
      "|    0   N/A  N/A      2685      G   /usr/bin/gnome-shell               62MiB |\n",
      "|    0   N/A  N/A      3609      G   ...703281151127485480,131072      317MiB |\n",
      "|    0   N/A  N/A     33146      G   ...RendererForSitePerProcess      208MiB |\n",
      "|    0   N/A  N/A     33874      C   ...da3/envs/tesis/bin/python     4695MiB |\n",
      "+-----------------------------------------------------------------------------+\n",
      "\n",
      "(19557777408, 25423577088)\n",
      "Sat Oct 15 23:21:44 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 515.65.01    Driver Version: 515.65.01    CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0  On |                  N/A |\n",
      "|  0%   54C    P2    90W / 350W |   5606MiB / 24576MiB |     15%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      2322      G   /usr/lib/xorg/Xorg                276MiB |\n",
      "|    0   N/A  N/A      2685      G   /usr/bin/gnome-shell               62MiB |\n",
      "|    0   N/A  N/A      3609      G   ...703281151127485480,131072      317MiB |\n",
      "|    0   N/A  N/A     33146      G   ...RendererForSitePerProcess      220MiB |\n",
      "|    0   N/A  N/A     33874      C   ...da3/envs/tesis/bin/python     4695MiB |\n",
      "+-----------------------------------------------------------------------------+\n",
      "\n",
      "(19545194496, 25423577088)\n",
      "Sat Oct 15 23:21:44 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 515.65.01    Driver Version: 515.65.01    CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0  On |                  N/A |\n",
      "|  0%   54C    P2   100W / 350W |   5606MiB / 24576MiB |     15%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      2322      G   /usr/lib/xorg/Xorg                276MiB |\n",
      "|    0   N/A  N/A      2685      G   /usr/bin/gnome-shell               62MiB |\n",
      "|    0   N/A  N/A      3609      G   ...703281151127485480,131072      317MiB |\n",
      "|    0   N/A  N/A     33146      G   ...RendererForSitePerProcess      220MiB |\n",
      "|    0   N/A  N/A     33874      C   ...da3/envs/tesis/bin/python     4695MiB |\n",
      "+-----------------------------------------------------------------------------+\n",
      "\n",
      "(19545194496, 25423577088)\n",
      "Sat Oct 15 23:21:45 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 515.65.01    Driver Version: 515.65.01    CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0  On |                  N/A |\n",
      "|  0%   54C    P2   110W / 350W |   5606MiB / 24576MiB |     16%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      2322      G   /usr/lib/xorg/Xorg                276MiB |\n",
      "|    0   N/A  N/A      2685      G   /usr/bin/gnome-shell               62MiB |\n",
      "|    0   N/A  N/A      3609      G   ...703281151127485480,131072      317MiB |\n",
      "|    0   N/A  N/A     33146      G   ...RendererForSitePerProcess      220MiB |\n",
      "|    0   N/A  N/A     33874      C   ...da3/envs/tesis/bin/python     4695MiB |\n",
      "+-----------------------------------------------------------------------------+\n",
      "\n",
      "(19545194496, 25423577088)\n",
      "Sat Oct 15 23:21:45 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 515.65.01    Driver Version: 515.65.01    CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0  On |                  N/A |\n",
      "|  0%   54C    P2   120W / 350W |   5606MiB / 24576MiB |     16%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      2322      G   /usr/lib/xorg/Xorg                276MiB |\n",
      "|    0   N/A  N/A      2685      G   /usr/bin/gnome-shell               62MiB |\n",
      "|    0   N/A  N/A      3609      G   ...703281151127485480,131072      317MiB |\n",
      "|    0   N/A  N/A     33146      G   ...RendererForSitePerProcess      220MiB |\n",
      "|    0   N/A  N/A     33874      C   ...da3/envs/tesis/bin/python     4695MiB |\n",
      "+-----------------------------------------------------------------------------+\n",
      "\n",
      "(19545194496, 25423577088)\n",
      "Sat Oct 15 23:21:45 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 515.65.01    Driver Version: 515.65.01    CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0  On |                  N/A |\n",
      "|  0%   54C    P2   120W / 350W |   5606MiB / 24576MiB |     16%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      2322      G   /usr/lib/xorg/Xorg                276MiB |\n",
      "|    0   N/A  N/A      2685      G   /usr/bin/gnome-shell               62MiB |\n",
      "|    0   N/A  N/A      3609      G   ...703281151127485480,131072      317MiB |\n",
      "|    0   N/A  N/A     33146      G   ...RendererForSitePerProcess      220MiB |\n",
      "|    0   N/A  N/A     33874      C   ...da3/envs/tesis/bin/python     4695MiB |\n",
      "+-----------------------------------------------------------------------------+\n",
      "\n",
      "Batch: 4263 \t 48902.25671696654 samples/sec\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4263, 48902.25671696654)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# probemos en la practica\n",
    "proc_time(max_batch_size_recommended,model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOTA IMPORTANTE\n",
    "\n",
    "revisando la documentacion, el hilo de stackoverflow, veo que la version es vieja.\n",
    "la nueva version summary, ya te dice cuanto va a a pesar el modelo considerando su input ... \n",
    "por eso es que la nueva version requiere eso,\n",
    "la anterior solamente te decia cuanto iba a pesar el modelo.\n",
    "pero la nueva considera la cantidad de datos de entramiento (batch) cuanto pesa cada uno dimension_imagen, y lo que pesa el propio modelo."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('tesis')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9abe774f74fe6e9a34c044080c00539c2573e8d4e4c28ec478136b0c7aa9cb53"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
