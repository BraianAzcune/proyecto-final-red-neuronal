{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error\n",
    "revisar las cuentas al instanciar el modelo, porque hay problemas de dimension entre las redes, puede ser culpa de dropout. probar.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-14 23:02:48,088\tINFO worker.py:1519 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "/home/braian/miniconda3/envs/tesis/lib/python3.9/site-packages/ray/tune/trainable/function_trainable.py:609: DeprecationWarning: `checkpoint_dir` in `func(config, checkpoint_dir)` is being deprecated. To save and load checkpoint in trainable functions, please use the `ray.air.session` API:\n",
      "\n",
      "from ray.air import session\n",
      "\n",
      "def train(config):\n",
      "    # ...\n",
      "    session.report({\"metric\": metric}, checkpoint=checkpoint)\n",
      "\n",
      "For more information please see https://docs.ray.io/en/master/tune/api_docs/trainable.html\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-11-14 23:02:48 (running for 00:00:00.16)\n",
      "Memory usage on this node: 5.1/15.4 GiB \n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 1.000: None\n",
      "Resources requested: 2.0/20 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /home/braian/ray_results/train_cifar_2022-11-14_23-02-48\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-------------------------+----------+--------------------+--------------+-----------------+----------------------+------------------------+----------------------+------------------------+-----------+-----------+\n",
      "| Trial name              | status   | loc                |   batch_size |   learning_rate |   cant_filtros_conv1 |   kernel_size_maxpool1 |   cant_filtros_conv2 |   kernel_size_maxpool2 |   full_l1 |   full_l2 |\n",
      "|-------------------------+----------+--------------------+--------------+-----------------+----------------------+------------------------+----------------------+------------------------+-----------+-----------|\n",
      "| train_cifar_9aac9_00000 | RUNNING  | 192.168.0.187:5923 |           16 |     0.000547441 |                   12 |                      3 |                   22 |                      3 |       120 |       124 |\n",
      "+-------------------------+----------+--------------------+--------------+-----------------+----------------------+------------------------+----------------------+------------------------+-----------+-----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(func pid=5923)\u001b[0m Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.0%\u001b[36m(func pid=5923)\u001b[0m \n",
      "0.0%\u001b[36m(func pid=5923)\u001b[0m \n",
      "0.1%\u001b[36m(func pid=5923)\u001b[0m \n",
      "0.2%\u001b[36m(func pid=5923)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-11-14 23:02:54 (running for 00:00:06.19)\n",
      "Memory usage on this node: 6.1/15.4 GiB \n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 1.000: None\n",
      "Resources requested: 2.0/20 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /home/braian/ray_results/train_cifar_2022-11-14_23-02-48\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-------------------------+----------+--------------------+--------------+-----------------+----------------------+------------------------+----------------------+------------------------+-----------+-----------+\n",
      "| Trial name              | status   | loc                |   batch_size |   learning_rate |   cant_filtros_conv1 |   kernel_size_maxpool1 |   cant_filtros_conv2 |   kernel_size_maxpool2 |   full_l1 |   full_l2 |\n",
      "|-------------------------+----------+--------------------+--------------+-----------------+----------------------+------------------------+----------------------+------------------------+-----------+-----------|\n",
      "| train_cifar_9aac9_00000 | RUNNING  | 192.168.0.187:5923 |           16 |     0.000547441 |                   12 |                      3 |                   22 |                      3 |       120 |       124 |\n",
      "+-------------------------+----------+--------------------+--------------+-----------------+----------------------+------------------------+----------------------+------------------------+-----------+-----------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.5%\u001b[36m(func pid=5923)\u001b[0m \n",
      "1.0%\u001b[36m(func pid=5923)\u001b[0m \n",
      "1.5%\u001b[36m(func pid=5923)\u001b[0m \n",
      "2.0%\u001b[36m(func pid=5923)\u001b[0m \n",
      "2.4%\u001b[36m(func pid=5923)\u001b[0m \n",
      "3.8%\u001b[36m(func pid=5923)\u001b[0m \n",
      "5.2%\u001b[36m(func pid=5923)\u001b[0m \n",
      "5.3%\u001b[36m(func pid=5923)\u001b[0m \n",
      "5.4%\u001b[36m(func pid=5923)\u001b[0m \n",
      "5.4%\u001b[36m(func pid=5923)\u001b[0m \n",
      "5.5%\u001b[36m(func pid=5923)\u001b[0m \n",
      "5.6%\u001b[36m(func pid=5923)\u001b[0m \n",
      "6.2%\u001b[36m(func pid=5923)\u001b[0m \n",
      "6.2%\u001b[36m(func pid=5923)\u001b[0m \n",
      "6.3%\u001b[36m(func pid=5923)\u001b[0m \n",
      "6.3%\u001b[36m(func pid=5923)\u001b[0m \n",
      "7.5%\u001b[36m(func pid=5923)\u001b[0m \n",
      "8.0%\u001b[36m(func pid=5923)\u001b[0m \n",
      "9.1%\u001b[36m(func pid=5923)\u001b[0m \n",
      "9.7%\u001b[36m(func pid=5923)\u001b[0m \n",
      "9.8%\u001b[36m(func pid=5923)\u001b[0m \n",
      "10.9%[36m(func pid=5923)\u001b[0m \n",
      "11.5%[36m(func pid=5923)\u001b[0m \n",
      "12.7%[36m(func pid=5923)\u001b[0m \n",
      "12.9%[36m(func pid=5923)\u001b[0m \n",
      "12.9%[36m(func pid=5923)\u001b[0m \n",
      "14.5%[36m(func pid=5923)\u001b[0m \n",
      "14.7%[36m(func pid=5923)\u001b[0m \n",
      "15.9%[36m(func pid=5923)\u001b[0m \n",
      "16.5%[36m(func pid=5923)\u001b[0m \n",
      "17.3%[36m(func pid=5923)\u001b[0m \n",
      "17.3%[36m(func pid=5923)\u001b[0m \n",
      "18.4%[36m(func pid=5923)\u001b[0m \n",
      "19.2%[36m(func pid=5923)\u001b[0m \n",
      "20.2%[36m(func pid=5923)\u001b[0m \n",
      "20.2%[36m(func pid=5923)\u001b[0m \n",
      "20.7%[36m(func pid=5923)\u001b[0m \n",
      "21.3%[36m(func pid=5923)\u001b[0m \n",
      "22.5%[36m(func pid=5923)\u001b[0m \n",
      "22.9%[36m(func pid=5923)\u001b[0m \n",
      "24.2%[36m(func pid=5923)\u001b[0m \n",
      "24.3%[36m(func pid=5923)\u001b[0m \n",
      "25.9%[36m(func pid=5923)\u001b[0m \n",
      "26.9%[36m(func pid=5923)\u001b[0m \n",
      "27.0%[36m(func pid=5923)\u001b[0m \n",
      "27.1%[36m(func pid=5923)\u001b[0m \n",
      "27.2%[36m(func pid=5923)\u001b[0m \n",
      "27.7%[36m(func pid=5923)\u001b[0m \n",
      "27.7%[36m(func pid=5923)\u001b[0m \n",
      "27.8%[36m(func pid=5923)\u001b[0m \n",
      "27.9%[36m(func pid=5923)\u001b[0m \n",
      "27.9%[36m(func pid=5923)\u001b[0m \n",
      "28.0%[36m(func pid=5923)\u001b[0m \n",
      "28.6%[36m(func pid=5923)\u001b[0m \n",
      "29.1%[36m(func pid=5923)\u001b[0m \n",
      "29.2%[36m(func pid=5923)\u001b[0m \n",
      "30.0%[36m(func pid=5923)\u001b[0m \n",
      "30.1%[36m(func pid=5923)\u001b[0m \n",
      "30.3%[36m(func pid=5923)\u001b[0m \n",
      "30.3%[36m(func pid=5923)\u001b[0m \n",
      "30.4%[36m(func pid=5923)\u001b[0m \n",
      "31.4%[36m(func pid=5923)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-11-14 23:02:59 (running for 00:00:11.20)\n",
      "Memory usage on this node: 6.1/15.4 GiB \n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 1.000: None\n",
      "Resources requested: 2.0/20 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /home/braian/ray_results/train_cifar_2022-11-14_23-02-48\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-------------------------+----------+--------------------+--------------+-----------------+----------------------+------------------------+----------------------+------------------------+-----------+-----------+\n",
      "| Trial name              | status   | loc                |   batch_size |   learning_rate |   cant_filtros_conv1 |   kernel_size_maxpool1 |   cant_filtros_conv2 |   kernel_size_maxpool2 |   full_l1 |   full_l2 |\n",
      "|-------------------------+----------+--------------------+--------------+-----------------+----------------------+------------------------+----------------------+------------------------+-----------+-----------|\n",
      "| train_cifar_9aac9_00000 | RUNNING  | 192.168.0.187:5923 |           16 |     0.000547441 |                   12 |                      3 |                   22 |                      3 |       120 |       124 |\n",
      "+-------------------------+----------+--------------------+--------------+-----------------+----------------------+------------------------+----------------------+------------------------+-----------+-----------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31.8%[36m(func pid=5923)\u001b[0m \n",
      "32.8%[36m(func pid=5923)\u001b[0m \n",
      "33.2%[36m(func pid=5923)\u001b[0m \n",
      "34.2%[36m(func pid=5923)\u001b[0m \n",
      "34.6%[36m(func pid=5923)\u001b[0m \n",
      "35.6%[36m(func pid=5923)\u001b[0m \n",
      "36.0%[36m(func pid=5923)\u001b[0m \n",
      "36.6%[36m(func pid=5923)\u001b[0m \n",
      "36.7%[36m(func pid=5923)\u001b[0m \n",
      "36.7%[36m(func pid=5923)\u001b[0m \n",
      "37.5%[36m(func pid=5923)\u001b[0m \n",
      "38.2%[36m(func pid=5923)\u001b[0m \n",
      "39.0%[36m(func pid=5923)\u001b[0m \n",
      "39.6%[36m(func pid=5923)\u001b[0m \n",
      "40.6%[36m(func pid=5923)\u001b[0m \n",
      "41.2%[36m(func pid=5923)\u001b[0m \n",
      "41.3%[36m(func pid=5923)\u001b[0m \n",
      "41.3%[36m(func pid=5923)\u001b[0m \n",
      "42.2%[36m(func pid=5923)\u001b[0m \n",
      "42.2%[36m(func pid=5923)\u001b[0m \n",
      "42.3%[36m(func pid=5923)\u001b[0m \n",
      "42.9%[36m(func pid=5923)\u001b[0m \n",
      "43.9%[36m(func pid=5923)\u001b[0m \n",
      "44.5%[36m(func pid=5923)\u001b[0m \n",
      "44.5%[36m(func pid=5923)\u001b[0m \n",
      "45.5%[36m(func pid=5923)\u001b[0m \n",
      "46.1%[36m(func pid=5923)\u001b[0m \n",
      "47.1%[36m(func pid=5923)\u001b[0m \n",
      "47.1%[36m(func pid=5923)\u001b[0m \n",
      "47.1%[36m(func pid=5923)\u001b[0m \n",
      "47.8%[36m(func pid=5923)\u001b[0m \n",
      "48.8%[36m(func pid=5923)\u001b[0m \n",
      "49.4%[36m(func pid=5923)\u001b[0m \n",
      "50.6%[36m(func pid=5923)\u001b[0m \n",
      "50.6%[36m(func pid=5923)\u001b[0m \n",
      "51.1%[36m(func pid=5923)\u001b[0m \n",
      "51.1%[36m(func pid=5923)\u001b[0m \n",
      "52.4%[36m(func pid=5923)\u001b[0m \n",
      "52.4%[36m(func pid=5923)\u001b[0m \n",
      "52.4%[36m(func pid=5923)\u001b[0m \n",
      "52.4%[36m(func pid=5923)\u001b[0m \n",
      "52.5%[36m(func pid=5923)\u001b[0m \n",
      "52.5%[36m(func pid=5923)\u001b[0m \n",
      "53.0%[36m(func pid=5923)\u001b[0m \n",
      "53.1%[36m(func pid=5923)\u001b[0m \n",
      "54.3%[36m(func pid=5923)\u001b[0m \n",
      "54.7%[36m(func pid=5923)\u001b[0m \n",
      "54.7%[36m(func pid=5923)\u001b[0m \n",
      "54.8%[36m(func pid=5923)\u001b[0m \n",
      "54.9%[36m(func pid=5923)\u001b[0m \n",
      "54.9%[36m(func pid=5923)\u001b[0m \n",
      "54.9%[36m(func pid=5923)\u001b[0m \n",
      "55.0%[36m(func pid=5923)\u001b[0m \n",
      "56.1%[36m(func pid=5923)\u001b[0m \n",
      "56.6%[36m(func pid=5923)\u001b[0m \n",
      "57.8%[36m(func pid=5923)\u001b[0m \n",
      "57.8%[36m(func pid=5923)\u001b[0m \n",
      "58.4%[36m(func pid=5923)\u001b[0m \n",
      "58.5%[36m(func pid=5923)\u001b[0m \n",
      "59.5%[36m(func pid=5923)\u001b[0m \n",
      "60.0%[36m(func pid=5923)\u001b[0m \n",
      "60.0%[36m(func pid=5923)\u001b[0m \n",
      "60.1%[36m(func pid=5923)\u001b[0m \n",
      "61.0%[36m(func pid=5923)\u001b[0m \n",
      "61.1%[36m(func pid=5923)\u001b[0m \n",
      "61.1%[36m(func pid=5923)\u001b[0m \n",
      "61.1%[36m(func pid=5923)\u001b[0m \n",
      "61.1%[36m(func pid=5923)\u001b[0m \n",
      "61.1%[36m(func pid=5923)\u001b[0m \n",
      "61.2%[36m(func pid=5923)\u001b[0m \n",
      "61.2%[36m(func pid=5923)\u001b[0m \n",
      "61.2%[36m(func pid=5923)\u001b[0m \n",
      "61.3%[36m(func pid=5923)\u001b[0m \n",
      "61.3%[36m(func pid=5923)\u001b[0m \n",
      "61.3%[36m(func pid=5923)\u001b[0m \n",
      "61.3%[36m(func pid=5923)\u001b[0m \n",
      "61.4%[36m(func pid=5923)\u001b[0m \n",
      "61.9%[36m(func pid=5923)\u001b[0m \n",
      "63.0%[36m(func pid=5923)\u001b[0m \n",
      "63.0%[36m(func pid=5923)\u001b[0m \n",
      "63.1%[36m(func pid=5923)\u001b[0m \n",
      "63.1%[36m(func pid=5923)\u001b[0m \n",
      "63.1%[36m(func pid=5923)\u001b[0m \n",
      "63.2%[36m(func pid=5923)\u001b[0m \n",
      "63.2%[36m(func pid=5923)\u001b[0m \n",
      "63.2%[36m(func pid=5923)\u001b[0m \n",
      "63.3%[36m(func pid=5923)\u001b[0m \n",
      "63.3%[36m(func pid=5923)\u001b[0m \n",
      "63.7%[36m(func pid=5923)\u001b[0m \n",
      "63.7%[36m(func pid=5923)\u001b[0m \n",
      "64.7%[36m(func pid=5923)\u001b[0m \n",
      "65.4%[36m(func pid=5923)\u001b[0m \n",
      "66.1%[36m(func pid=5923)\u001b[0m \n",
      "66.1%[36m(func pid=5923)\u001b[0m \n",
      "67.1%[36m(func pid=5923)\u001b[0m \n",
      "67.1%[36m(func pid=5923)\u001b[0m \n",
      "67.1%[36m(func pid=5923)\u001b[0m \n",
      "67.7%[36m(func pid=5923)\u001b[0m \n",
      "67.7%[36m(func pid=5923)\u001b[0m \n",
      "67.7%[36m(func pid=5923)\u001b[0m \n",
      "68.7%[36m(func pid=5923)\u001b[0m \n",
      "68.8%[36m(func pid=5923)\u001b[0m \n",
      "68.8%[36m(func pid=5923)\u001b[0m \n",
      "68.8%[36m(func pid=5923)\u001b[0m \n",
      "68.9%[36m(func pid=5923)\u001b[0m \n",
      "68.9%[36m(func pid=5923)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-11-14 23:03:04 (running for 00:00:16.20)\n",
      "Memory usage on this node: 6.1/15.4 GiB \n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 1.000: None\n",
      "Resources requested: 2.0/20 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /home/braian/ray_results/train_cifar_2022-11-14_23-02-48\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-------------------------+----------+--------------------+--------------+-----------------+----------------------+------------------------+----------------------+------------------------+-----------+-----------+\n",
      "| Trial name              | status   | loc                |   batch_size |   learning_rate |   cant_filtros_conv1 |   kernel_size_maxpool1 |   cant_filtros_conv2 |   kernel_size_maxpool2 |   full_l1 |   full_l2 |\n",
      "|-------------------------+----------+--------------------+--------------+-----------------+----------------------+------------------------+----------------------+------------------------+-----------+-----------|\n",
      "| train_cifar_9aac9_00000 | RUNNING  | 192.168.0.187:5923 |           16 |     0.000547441 |                   12 |                      3 |                   22 |                      3 |       120 |       124 |\n",
      "+-------------------------+----------+--------------------+--------------+-----------------+----------------------+------------------------+----------------------+------------------------+-----------+-----------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "69.5%[36m(func pid=5923)\u001b[0m \n",
      "69.6%[36m(func pid=5923)\u001b[0m \n",
      "69.6%[36m(func pid=5923)\u001b[0m \n",
      "69.6%[36m(func pid=5923)\u001b[0m \n",
      "69.6%[36m(func pid=5923)\u001b[0m \n",
      "69.7%[36m(func pid=5923)\u001b[0m \n",
      "69.7%[36m(func pid=5923)\u001b[0m \n",
      "69.7%[36m(func pid=5923)\u001b[0m \n",
      "69.8%[36m(func pid=5923)\u001b[0m \n",
      "70.7%[36m(func pid=5923)\u001b[0m \n",
      "70.7%[36m(func pid=5923)\u001b[0m \n",
      "71.2%[36m(func pid=5923)\u001b[0m \n",
      "71.2%[36m(func pid=5923)\u001b[0m \n",
      "72.4%[36m(func pid=5923)\u001b[0m \n",
      "72.7%[36m(func pid=5923)\u001b[0m \n",
      "72.8%[36m(func pid=5923)\u001b[0m \n",
      "72.9%[36m(func pid=5923)\u001b[0m \n",
      "72.9%[36m(func pid=5923)\u001b[0m \n",
      "72.9%[36m(func pid=5923)\u001b[0m \n",
      "73.0%[36m(func pid=5923)\u001b[0m \n",
      "73.0%[36m(func pid=5923)\u001b[0m \n",
      "73.0%[36m(func pid=5923)\u001b[0m \n",
      "73.1%[36m(func pid=5923)\u001b[0m \n",
      "74.2%[36m(func pid=5923)\u001b[0m \n",
      "74.6%[36m(func pid=5923)\u001b[0m \n",
      "74.7%[36m(func pid=5923)\u001b[0m \n",
      "74.7%[36m(func pid=5923)\u001b[0m \n",
      "74.8%[36m(func pid=5923)\u001b[0m \n",
      "74.8%[36m(func pid=5923)\u001b[0m \n",
      "74.8%[36m(func pid=5923)\u001b[0m \n",
      "74.8%[36m(func pid=5923)\u001b[0m \n",
      "74.9%[36m(func pid=5923)\u001b[0m \n",
      "74.9%[36m(func pid=5923)\u001b[0m \n",
      "76.0%[36m(func pid=5923)\u001b[0m \n",
      "76.5%[36m(func pid=5923)\u001b[0m \n",
      "76.6%[36m(func pid=5923)\u001b[0m \n",
      "76.6%[36m(func pid=5923)\u001b[0m \n",
      "76.7%[36m(func pid=5923)\u001b[0m \n",
      "76.7%[36m(func pid=5923)\u001b[0m \n",
      "76.7%[36m(func pid=5923)\u001b[0m \n",
      "76.7%[36m(func pid=5923)\u001b[0m \n",
      "76.8%[36m(func pid=5923)\u001b[0m \n",
      "77.8%[36m(func pid=5923)\u001b[0m \n",
      "78.3%[36m(func pid=5923)\u001b[0m \n",
      "79.5%[36m(func pid=5923)\u001b[0m \n",
      "79.5%[36m(func pid=5923)\u001b[0m \n",
      "80.1%[36m(func pid=5923)\u001b[0m \n",
      "80.2%[36m(func pid=5923)\u001b[0m \n",
      "80.5%[36m(func pid=5923)\u001b[0m \n",
      "80.6%[36m(func pid=5923)\u001b[0m \n",
      "81.9%[36m(func pid=5923)\u001b[0m \n",
      "82.0%[36m(func pid=5923)\u001b[0m \n",
      "82.1%[36m(func pid=5923)\u001b[0m \n",
      "83.8%[36m(func pid=5923)\u001b[0m \n",
      "85.1%[36m(func pid=5923)\u001b[0m \n",
      "85.2%[36m(func pid=5923)\u001b[0m \n",
      "85.2%[36m(func pid=5923)\u001b[0m \n",
      "85.2%[36m(func pid=5923)\u001b[0m \n",
      "85.6%[36m(func pid=5923)\u001b[0m \n",
      "85.8%[36m(func pid=5923)\u001b[0m \n",
      "87.2%[36m(func pid=5923)\u001b[0m \n",
      "87.6%[36m(func pid=5923)\u001b[0m \n",
      "88.9%[36m(func pid=5923)\u001b[0m \n",
      "88.9%[36m(func pid=5923)\u001b[0m \n",
      "89.0%[36m(func pid=5923)\u001b[0m \n",
      "89.5%[36m(func pid=5923)\u001b[0m \n",
      "90.6%[36m(func pid=5923)\u001b[0m \n",
      "91.4%[36m(func pid=5923)\u001b[0m \n",
      "91.4%[36m(func pid=5923)\u001b[0m \n",
      "91.5%[36m(func pid=5923)\u001b[0m \n",
      "91.5%[36m(func pid=5923)\u001b[0m \n",
      "91.7%[36m(func pid=5923)\u001b[0m \n",
      "93.4%[36m(func pid=5923)\u001b[0m \n",
      "93.4%[36m(func pid=5923)\u001b[0m \n",
      "93.6%[36m(func pid=5923)\u001b[0m \n",
      "94.9%[36m(func pid=5923)\u001b[0m \n",
      "95.0%[36m(func pid=5923)\u001b[0m \n",
      "95.1%[36m(func pid=5923)\u001b[0m \n",
      "95.2%[36m(func pid=5923)\u001b[0m \n",
      "95.5%[36m(func pid=5923)\u001b[0m \n",
      "95.7%[36m(func pid=5923)\u001b[0m \n",
      "97.2%[36m(func pid=5923)\u001b[0m \n",
      "97.5%[36m(func pid=5923)\u001b[0m \n",
      "97.5%[36m(func pid=5923)\u001b[0m \n",
      "97.6%[36m(func pid=5923)\u001b[0m \n",
      "99.2%[36m(func pid=5923)\u001b[0m \n",
      "99.4%[36m(func pid=5923)\u001b[0m \n",
      "100.0%36m(func pid=5923)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(func pid=5923)\u001b[0m Extracting ./data/cifar-10-python.tar.gz to ./data\n",
      "== Status ==\n",
      "Current time: 2022-11-14 23:03:09 (running for 00:00:21.21)\n",
      "Memory usage on this node: 6.1/15.4 GiB \n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 1.000: None\n",
      "Resources requested: 2.0/20 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /home/braian/ray_results/train_cifar_2022-11-14_23-02-48\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-------------------------+----------+--------------------+--------------+-----------------+----------------------+------------------------+----------------------+------------------------+-----------+-----------+\n",
      "| Trial name              | status   | loc                |   batch_size |   learning_rate |   cant_filtros_conv1 |   kernel_size_maxpool1 |   cant_filtros_conv2 |   kernel_size_maxpool2 |   full_l1 |   full_l2 |\n",
      "|-------------------------+----------+--------------------+--------------+-----------------+----------------------+------------------------+----------------------+------------------------+-----------+-----------|\n",
      "| train_cifar_9aac9_00000 | RUNNING  | 192.168.0.187:5923 |           16 |     0.000547441 |                   12 |                      3 |                   22 |                      3 |       120 |       124 |\n",
      "+-------------------------+----------+--------------------+--------------+-----------------+----------------------+------------------------+----------------------+------------------------+-----------+-----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(func pid=5923)\u001b[0m Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-14 23:03:12,896\tERROR trial_runner.py:993 -- Trial train_cifar_9aac9_00000: Error processing event.\n",
      "ray.exceptions.RayTaskError(RuntimeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=5923, ip=192.168.0.187, repr=func)\n",
      "  File \"/home/braian/miniconda3/envs/tesis/lib/python3.9/site-packages/ray/tune/trainable/trainable.py\", line 355, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/braian/miniconda3/envs/tesis/lib/python3.9/site-packages/ray/tune/trainable/function_trainable.py\", line 325, in entrypoint\n",
      "    return self._trainable_func(\n",
      "  File \"/home/braian/miniconda3/envs/tesis/lib/python3.9/site-packages/ray/tune/trainable/function_trainable.py\", line 651, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/tmp/ipykernel_5151/3099951089.py\", line 144, in train_cifar\n",
      "  File \"/tmp/ipykernel_5151/3099951089.py\", line 168, in train_loop\n",
      "  File \"/home/braian/miniconda3/envs/tesis/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/braian/Documents/tesis-red-neuronal/modelo_convolucional.py\", line 62, in forward\n",
      "    logits = self.denseLayer(logits)\n",
      "  File \"/home/braian/miniconda3/envs/tesis/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/braian/miniconda3/envs/tesis/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n",
      "    input = module(input)\n",
      "  File \"/home/braian/miniconda3/envs/tesis/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/braian/miniconda3/envs/tesis/lib/python3.9/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "RuntimeError: mat1 and mat2 shapes cannot be multiplied (16x550 and 352x120)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th>date               </th><th>experiment_id                   </th><th>hostname       </th><th>node_ip      </th><th style=\"text-align: right;\">  pid</th><th style=\"text-align: right;\">  timestamp</th><th>trial_id   </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_cifar_9aac9_00000</td><td>2022-11-14_23-02-49</td><td>be284bb5b4a64a23afb78ea5d037e431</td><td>braian-pc-linux</td><td>192.168.0.187</td><td style=\"text-align: right;\"> 5923</td><td style=\"text-align: right;\"> 1668477769</td><td>9aac9_00000</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-11-14 23:03:12 (running for 00:00:24.26)\n",
      "Memory usage on this node: 8.4/15.4 GiB \n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 1.000: None\n",
      "Resources requested: 0/20 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /home/braian/ray_results/train_cifar_2022-11-14_23-02-48\n",
      "Number of trials: 1/1 (1 ERROR)\n",
      "+-------------------------+----------+--------------------+--------------+-----------------+----------------------+------------------------+----------------------+------------------------+-----------+-----------+\n",
      "| Trial name              | status   | loc                |   batch_size |   learning_rate |   cant_filtros_conv1 |   kernel_size_maxpool1 |   cant_filtros_conv2 |   kernel_size_maxpool2 |   full_l1 |   full_l2 |\n",
      "|-------------------------+----------+--------------------+--------------+-----------------+----------------------+------------------------+----------------------+------------------------+-----------+-----------|\n",
      "| train_cifar_9aac9_00000 | ERROR    | 192.168.0.187:5923 |           16 |     0.000547441 |                   12 |                      3 |                   22 |                      3 |       120 |       124 |\n",
      "+-------------------------+----------+--------------------+--------------+-----------------+----------------------+------------------------+----------------------+------------------------+-----------+-----------+\n",
      "Number of errored trials: 1\n",
      "+-------------------------+--------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| Trial name              |   # failures | error file                                                                                                                                                                                                                |\n",
      "|-------------------------+--------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
      "| train_cifar_9aac9_00000 |            1 | /home/braian/ray_results/train_cifar_2022-11-14_23-02-48/train_cifar_9aac9_00000_0_batch_size=16,cant_filtros_conv1=12,cant_filtros_conv2=22,full_l1=120,full_l2=124,kernel_size_maxpool1=3_2022-11-14_23-02-48/error.txt |\n",
      "+-------------------------+--------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    },
    {
     "ename": "TuneError",
     "evalue": "('Trials did not complete', [train_cifar_9aac9_00000])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTuneError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/braian/Documents/tesis-red-neuronal/ajustar_hiperparametros.ipynb Cell 2\u001b[0m in \u001b[0;36m<cell line: 207>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/braian/Documents/tesis-red-neuronal/ajustar_hiperparametros.ipynb#W1sZmlsZQ%3D%3D?line=203'>204</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m loss, accuracy\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/braian/Documents/tesis-red-neuronal/ajustar_hiperparametros.ipynb#W1sZmlsZQ%3D%3D?line=206'>207</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/braian/Documents/tesis-red-neuronal/ajustar_hiperparametros.ipynb#W1sZmlsZQ%3D%3D?line=207'>208</a>\u001b[0m     \u001b[39m# You can change the number of GPUs per trial here:\u001b[39;00m\n\u001b[0;32m--> <a href='vscode-notebook-cell:/home/braian/Documents/tesis-red-neuronal/ajustar_hiperparametros.ipynb#W1sZmlsZQ%3D%3D?line=208'>209</a>\u001b[0m     main(num_samples\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, max_num_epochs\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, gpus_per_trial\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
      "\u001b[1;32m/home/braian/Documents/tesis-red-neuronal/ajustar_hiperparametros.ipynb Cell 2\u001b[0m in \u001b[0;36mmain\u001b[0;34m(num_samples, max_num_epochs, gpus_per_trial)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/braian/Documents/tesis-red-neuronal/ajustar_hiperparametros.ipynb#W1sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m scheduler \u001b[39m=\u001b[39m ASHAScheduler(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/braian/Documents/tesis-red-neuronal/ajustar_hiperparametros.ipynb#W1sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m     metric\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/braian/Documents/tesis-red-neuronal/ajustar_hiperparametros.ipynb#W1sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m     mode\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmin\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/braian/Documents/tesis-red-neuronal/ajustar_hiperparametros.ipynb#W1sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m     max_t\u001b[39m=\u001b[39mmax_num_epochs,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/braian/Documents/tesis-red-neuronal/ajustar_hiperparametros.ipynb#W1sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m     grace_period\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/braian/Documents/tesis-red-neuronal/ajustar_hiperparametros.ipynb#W1sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m     reduction_factor\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/braian/Documents/tesis-red-neuronal/ajustar_hiperparametros.ipynb#W1sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m reporter \u001b[39m=\u001b[39m CLIReporter(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/braian/Documents/tesis-red-neuronal/ajustar_hiperparametros.ipynb#W1sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m     parameter_columns\u001b[39m=\u001b[39m\u001b[39mlist\u001b[39m(config\u001b[39m.\u001b[39mkeys()),\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/braian/Documents/tesis-red-neuronal/ajustar_hiperparametros.ipynb#W1sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m     metric_columns\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mtraining_iteration\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/braian/Documents/tesis-red-neuronal/ajustar_hiperparametros.ipynb#W1sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m result \u001b[39m=\u001b[39m tune\u001b[39m.\u001b[39;49mrun(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/braian/Documents/tesis-red-neuronal/ajustar_hiperparametros.ipynb#W1sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m     \u001b[39m# partial es una funcion de orden superior de tipo curry\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/braian/Documents/tesis-red-neuronal/ajustar_hiperparametros.ipynb#W1sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m     partial(train_cifar, data_dir\u001b[39m=\u001b[39;49mdata_dir, checkpoint_dir\u001b[39m=\u001b[39;49mcheckpoint_dir),\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/braian/Documents/tesis-red-neuronal/ajustar_hiperparametros.ipynb#W1sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m     resources_per_trial\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mcpu\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m2\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mgpu\u001b[39;49m\u001b[39m\"\u001b[39;49m: gpus_per_trial},\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/braian/Documents/tesis-red-neuronal/ajustar_hiperparametros.ipynb#W1sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m     config\u001b[39m=\u001b[39;49mconfig,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/braian/Documents/tesis-red-neuronal/ajustar_hiperparametros.ipynb#W1sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m     num_samples\u001b[39m=\u001b[39;49mnum_samples,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/braian/Documents/tesis-red-neuronal/ajustar_hiperparametros.ipynb#W1sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m     scheduler\u001b[39m=\u001b[39;49mscheduler,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/braian/Documents/tesis-red-neuronal/ajustar_hiperparametros.ipynb#W1sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m     progress_reporter\u001b[39m=\u001b[39;49mreporter)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/braian/Documents/tesis-red-neuronal/ajustar_hiperparametros.ipynb#W1sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m best_trial \u001b[39m=\u001b[39m result\u001b[39m.\u001b[39mget_best_trial(\u001b[39m\"\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmin\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mlast\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/braian/Documents/tesis-red-neuronal/ajustar_hiperparametros.ipynb#W1sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mBest trial config: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(best_trial\u001b[39m.\u001b[39mconfig))\n",
      "File \u001b[0;32m~/miniconda3/envs/tesis/lib/python3.9/site-packages/ray/tune/tune.py:771\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(run_or_experiment, name, metric, mode, stop, time_budget_s, config, resources_per_trial, num_samples, local_dir, search_alg, scheduler, keep_checkpoints_num, checkpoint_score_attr, checkpoint_freq, checkpoint_at_end, verbose, progress_reporter, log_to_file, trial_name_creator, trial_dirname_creator, sync_config, export_formats, max_failures, fail_fast, restore, server_port, resume, reuse_actors, trial_executor, raise_on_failed_trial, callbacks, max_concurrent_trials, _experiment_checkpoint_dir, _remote)\u001b[0m\n\u001b[1;32m    769\u001b[0m \u001b[39mif\u001b[39;00m incomplete_trials:\n\u001b[1;32m    770\u001b[0m     \u001b[39mif\u001b[39;00m raise_on_failed_trial \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m state[\u001b[39m\"\u001b[39m\u001b[39msignal\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[0;32m--> 771\u001b[0m         \u001b[39mraise\u001b[39;00m TuneError(\u001b[39m\"\u001b[39m\u001b[39mTrials did not complete\u001b[39m\u001b[39m\"\u001b[39m, incomplete_trials)\n\u001b[1;32m    772\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    773\u001b[0m         logger\u001b[39m.\u001b[39merror(\u001b[39m\"\u001b[39m\u001b[39mTrials did not complete: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, incomplete_trials)\n",
      "\u001b[0;31mTuneError\u001b[0m: ('Trials did not complete', [train_cifar_9aac9_00000])"
     ]
    }
   ],
   "source": [
    "# python\n",
    "import os\n",
    "from functools import partial\n",
    "# pytorch\n",
    "import torch\n",
    "from torch import nn\n",
    "# pytorch utilidades\n",
    "from torch.utils.data import random_split\n",
    "# ray\n",
    "from ray import tune\n",
    "from ray.tune import CLIReporter\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "# yo\n",
    "from cargar_datos import cargar_datasets, cargar_dataloaders\n",
    "from modelo_convolucional import instanciarRed\n",
    "\n",
    "\n",
    "def main(num_samples=10, max_num_epochs=10, gpus_per_trial=0):\n",
    "    data_dir = os.path.abspath(\"./data\")\n",
    "    checkpoint_dir = os.path.abspath(\"./checkpoint_dir\")\n",
    "\n",
    "    # se carga una vez, para que si no esta descargado, se descarge y se valide, el resto de veces en las pruebas, se saltara esta parte.\n",
    "    cargar_datasets(data_dir)\n",
    "    \"\"\"\n",
    "    variable de configuracion, Ray tune modificara sus valores en el proceso de ajuste de hiperparametros.\n",
    "    \"\"\"\n",
    "    config = {\n",
    "        \"batch_size\": tune.choice([8, 16, 32]),\n",
    "        \"learning_rate\": tune.loguniform(1e-4, 1e-1),\n",
    "        # red convolucional\n",
    "        \"cant_filtros_conv1\": tune.choice([6, 12, 18]),\n",
    "        \"kernel_size_maxpool1\": tune.choice([2, 3]),\n",
    "        \"cant_filtros_conv2\": tune.choice([16, 22, 28]),\n",
    "        \"kernel_size_maxpool2\": tune.choice([2, 3]),\n",
    "        \"full_l1\": tune.choice([120, 140, 160]),\n",
    "        \"full_l2\": tune.choice([84, 104, 124])\n",
    "    }\n",
    "    \"\"\"\n",
    "    configurar Ray y correr las pruebas en busqueda de hiperparametros\n",
    "    \"\"\"\n",
    "    scheduler = ASHAScheduler(\n",
    "        metric=\"loss\",\n",
    "        mode=\"min\",\n",
    "        max_t=max_num_epochs,\n",
    "        grace_period=1,\n",
    "        reduction_factor=2)\n",
    "    reporter = CLIReporter(\n",
    "        parameter_columns=list(config.keys()),\n",
    "        metric_columns=[\"loss\", \"accuracy\", \"training_iteration\"])\n",
    "    result = tune.run(\n",
    "        # partial es una funcion de orden superior de tipo curry\n",
    "        partial(train_cifar, data_dir=data_dir, checkpoint_dir=checkpoint_dir),\n",
    "        resources_per_trial={\"cpu\": 2, \"gpu\": gpus_per_trial},\n",
    "        config=config,\n",
    "        num_samples=num_samples,\n",
    "        scheduler=scheduler,\n",
    "        progress_reporter=reporter)\n",
    "\n",
    "    best_trial = result.get_best_trial(\"loss\", \"min\", \"last\")\n",
    "    print(\"Best trial config: {}\".format(best_trial.config))\n",
    "    print(\"Best trial final validation loss: {}\".format(\n",
    "        best_trial.last_result[\"loss\"]))\n",
    "    print(\"Best trial final validation accuracy: {}\".format(\n",
    "        best_trial.last_result[\"accuracy\"]))\n",
    "\n",
    "    \"\"\"\n",
    "    Validar el desempeño de la red con mejor puntuacion en la busqueda de hiperparametros contra el conjunto de datos de validacion.\n",
    "    \"\"\"\n",
    "    best_trained_model = instanciarRed(best_trial.config)\n",
    "    device = getDevice()\n",
    "    best_trained_model.to(device)\n",
    "\n",
    "    best_checkpoint_dir = best_trial.checkpoint.value\n",
    "    model_state, optimizer_state = torch.load(os.path.join(\n",
    "        best_checkpoint_dir, \"checkpoint\"))\n",
    "    best_trained_model.load_state_dict(model_state)\n",
    "\n",
    "    test_acc = test_accuracy(best_trained_model, device, data_dir)\n",
    "    print(\"Best trial test set accuracy: {}\".format(test_acc))\n",
    "\n",
    "\n",
    "def test_accuracy(model, device=\"cpu\", data_dir=\"./data\"):\n",
    "    _, testset = cargar_datasets(data_dir)\n",
    "    testloader = cargar_dataloaders(testset, 4)\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    # pone a la red en moodo evaluacion, desactiva capas dropout.\n",
    "    model.eval()\n",
    "    # desactiva el proceso de calculo y guardado de valores intermedios\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return correct / total\n",
    "\n",
    "\n",
    "def getDevice():\n",
    "    device = \"cpu\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda:0\"\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            raise Exception(\n",
    "                \"la pc cuenta con multiples gpus, deberia utilizar DataParallel\")\n",
    "            #model = nn.DataParallel(model)\n",
    "    return device\n",
    "\n",
    "\n",
    "def train_cifar(config, checkpoint_dir=None, data_dir=None):\n",
    "    model = instanciarRed(config)\n",
    "\n",
    "    device = getDevice()\n",
    "    # le dice a Pytorch donde debe ejecutar el modelo.\n",
    "    model.to(device)\n",
    "    # CrossEntropyLoss requiere el output \"logits\", no es necesario pasarlo por el softmax, ya que lo calcula dentro. https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # se necesita enviar los parametros del modelo al optimizador para que los pueda actualizar.\n",
    "    optimizer = torch.optim.Adam(\n",
    "        model.parameters(), lr=config[\"learning_rate\"])\n",
    "\n",
    "    if checkpoint_dir:\n",
    "        model_state, optimizer_state = torch.load(\n",
    "            os.path.join(checkpoint_dir, \"checkpoint\"))\n",
    "        model.load_state_dict(model_state)\n",
    "        optimizer.load_state_dict(optimizer_state)\n",
    "\n",
    "    trainset, _ = cargar_datasets(data_dir)\n",
    "    # reservar una parte de los datos de entrenamiento para validacion.\n",
    "    test_abs = int(len(trainset) * 0.8)\n",
    "    train_subset, val_subset = random_split(\n",
    "        trainset, [test_abs, len(trainset) - test_abs])\n",
    "\n",
    "    trainloader = cargar_dataloaders(train_subset, config[\"batch_size\"])\n",
    "    valloader = cargar_dataloaders(val_subset, config[\"batch_size\"])\n",
    "\n",
    "    for epoch in range(10):  # loop over the dataset multiple times\n",
    "\n",
    "        train_loop(model, device, trainloader, criterion, optimizer, epoch)\n",
    "        loss, accuracy = validation_loss(model, device, valloader, criterion)\n",
    "\n",
    "        with tune.checkpoint_dir(epoch) as checkpoint_dir:\n",
    "            path = os.path.join(checkpoint_dir, \"checkpoint\")\n",
    "            torch.save((model.state_dict(), optimizer.state_dict()), path)\n",
    "\n",
    "        tune.report(loss=loss, accuracy=accuracy)\n",
    "    print(\"Finished Training\")\n",
    "\n",
    "\n",
    "def train_loop(model, device, trainloader, criterion, optimizer, epoch):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    epoch_steps = 0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        epoch_steps += 1\n",
    "        if i % 2000 == 1999:  # print every 2000 mini-batches\n",
    "            print(\"[%d, %5d] loss: %.3f\" % (epoch + 1, i + 1,\n",
    "                                            running_loss / epoch_steps))\n",
    "            running_loss = 0.0\n",
    "\n",
    "\n",
    "def validation_loss(net, device, valloader, criterion):\n",
    "    val_loss = 0.0\n",
    "    val_steps = 0\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    net.eval()\n",
    "    for i, data in enumerate(valloader, 0):\n",
    "\n",
    "        with torch.no_grad():\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            outputs = net(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.cpu().numpy()\n",
    "            val_steps += 1\n",
    "    loss = val_loss / val_steps\n",
    "    accuracy = correct / total\n",
    "    return loss, accuracy\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # You can change the number of GPUs per trial here:\n",
    "    main(num_samples=1, max_num_epochs=1, gpus_per_trial=1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('tesis')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9abe774f74fe6e9a34c044080c00539c2573e8d4e4c28ec478136b0c7aa9cb53"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
