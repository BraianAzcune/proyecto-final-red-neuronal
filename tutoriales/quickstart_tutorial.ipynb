{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "`Learn the Basics <intro.html>`_ ||\n",
        "**Quickstart** ||\n",
        "`Tensors <tensorqs_tutorial.html>`_ ||\n",
        "`Datasets & DataLoaders <data_tutorial.html>`_ ||\n",
        "`Transforms <transforms_tutorial.html>`_ ||\n",
        "`Build Model <buildmodel_tutorial.html>`_ ||\n",
        "`Autograd <autogradqs_tutorial.html>`_ ||\n",
        "`Optimization <optimization_tutorial.html>`_ ||\n",
        "`Save & Load Model <saveloadrun_tutorial.html>`_\n",
        "\n",
        "Quickstart\n",
        "===================\n",
        "This section runs through the API for common tasks in machine learning. Refer to the links in each section to dive deeper.\n",
        "\n",
        "Working with data\n",
        "-----------------\n",
        "PyTorch has two `primitives to work with data <https://pytorch.org/docs/stable/data.html>`_:\n",
        "``torch.utils.data.DataLoader`` and ``torch.utils.data.Dataset``.\n",
        "``Dataset`` stores the samples and their corresponding labels, and ``DataLoader`` wraps an iterable around\n",
        "the ``Dataset``.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "PyTorch offers domain-specific libraries such as `TorchText <https://pytorch.org/text/stable/index.html>`_,\n",
        "`TorchVision <https://pytorch.org/vision/stable/index.html>`_, and `TorchAudio <https://pytorch.org/audio/stable/index.html>`_,\n",
        "all of which include datasets. For this tutorial, we  will be using a TorchVision dataset.\n",
        "\n",
        "The ``torchvision.datasets`` module contains ``Dataset`` objects for many real-world vision data like\n",
        "CIFAR, COCO (`full list here <https://pytorch.org/vision/stable/datasets.html>`_). In this tutorial, we\n",
        "use the FashionMNIST dataset. Every TorchVision ``Dataset`` includes two arguments: ``transform`` and\n",
        "``target_transform`` to modify the samples and labels respectively.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100.0%\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100.0%\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100.0%\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100.0%"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Download training data from open datasets.\n",
        "training_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")\n",
        "\n",
        "# Download test data from open datasets.\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We pass the ``Dataset`` as an argument to ``DataLoader``. This wraps an iterable over our dataset, and supports\n",
        "automatic batching, sampling, shuffling and multiprocess data loading. Here we define a batch size of 64, i.e. each element\n",
        "in the dataloader iterable will return a batch of 64 features and labels.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
            "Shape of y: torch.Size([64]) torch.int64\n"
          ]
        }
      ],
      "source": [
        "batch_size = 64\n",
        "\n",
        "# Create data loaders.\n",
        "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
        "\n",
        "for X, y in test_dataloader:\n",
        "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
        "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Mostremos algunas imagenes\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "numeric labels: tensor([9, 2, 1, 1, 6])\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from torchvision.utils import make_grid\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5 # aclaramos la imagen\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "\n",
        "mi_loader = DataLoader(test_data, batch_size=5)\n",
        "\n",
        "iterador =  iter(mi_loader)\n",
        "\n",
        "primera_tanda = next(iterador)\n",
        "\n",
        "imshow(make_grid(primera_tanda[0]))\n",
        "print(\"numeric labels:\",primera_tanda[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "--------------\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Creating Models\n",
        "------------------\n",
        "To define a neural network in PyTorch, we create a class that inherits\n",
        "from `nn.Module <https://pytorch.org/docs/stable/generated/torch.nn.Module.html>`_. We define the layers of the network\n",
        "in the ``__init__`` function and specify how data will pass through the network in the ``forward`` function. To accelerate\n",
        "operations in the neural network, we move it to the GPU if available.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cuda device\n",
            "NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Get cpu or gpu device for training.\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")\n",
        "\n",
        "# Define model\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        # estilo Python 2\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        # estilo Python 3\n",
        "        # super().__init__()\n",
        "        # transforma la imagen de 28x28 a 1x784\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(28*28, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits\n",
        "\n",
        "model = NeuralNetwork().to(device)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Read more about `building neural networks in PyTorch <buildmodel_tutorial.html>`_.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "--------------\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Optimizing the Model Parameters\n",
        "----------------------------------------\n",
        "To train a model, we need a `loss function <https://pytorch.org/docs/stable/nn.html#loss-functions>`_\n",
        "and an `optimizer <https://pytorch.org/docs/stable/optim.html>`_.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In a single training loop, the model makes predictions on the training dataset (fed to it in batches), and\n",
        "backpropagates the prediction error to adjust the model's parameters.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# ? debugging ver memoria gpu usada\n",
        "# import torch.cuda as cutorch\n",
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        # ? ver memoria usada por la gpu antes.\n",
        "        #print(cutorch.memory_allocated(device=device))\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        # ? ver memoria de la gpu usda despues de cargar los datos.\n",
        "        # print(cutorch.memory_allocated(device=device))\n",
        "        # Compute prediction error\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), batch * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We also check the model's performance against the test dataset to ensure it is learning.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def test(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    model.eval()\n",
        "    test_loss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The training process is conducted over several iterations (*epochs*). During each epoch, the model learns\n",
        "parameters to make better predictions. We print the model's accuracy and loss at each epoch; we'd like to see the\n",
        "accuracy increase and the loss decrease with every epoch.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 0.653318  [    0/60000]\n",
            "loss: 0.743072  [ 6400/60000]\n",
            "loss: 0.518148  [12800/60000]\n",
            "loss: 0.746764  [19200/60000]\n",
            "loss: 0.659197  [25600/60000]\n",
            "loss: 0.642440  [32000/60000]\n",
            "loss: 0.707557  [38400/60000]\n",
            "loss: 0.724796  [44800/60000]\n",
            "loss: 0.714585  [51200/60000]\n",
            "loss: 0.679700  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 76.2%, Avg loss: 0.674417 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 0.632993  [    0/60000]\n",
            "loss: 0.724067  [ 6400/60000]\n",
            "loss: 0.501481  [12800/60000]\n",
            "loss: 0.733442  [19200/60000]\n",
            "loss: 0.647692  [25600/60000]\n",
            "loss: 0.630576  [32000/60000]\n",
            "loss: 0.690735  [38400/60000]\n",
            "loss: 0.714006  [44800/60000]\n",
            "loss: 0.702925  [51200/60000]\n",
            "loss: 0.666328  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 76.8%, Avg loss: 0.660723 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 0.614505  [    0/60000]\n",
            "loss: 0.706467  [ 6400/60000]\n",
            "loss: 0.486461  [12800/60000]\n",
            "loss: 0.721008  [19200/60000]\n",
            "loss: 0.637440  [25600/60000]\n",
            "loss: 0.619996  [32000/60000]\n",
            "loss: 0.675127  [38400/60000]\n",
            "loss: 0.704156  [44800/60000]\n",
            "loss: 0.692501  [51200/60000]\n",
            "loss: 0.653933  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 77.5%, Avg loss: 0.648021 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 0.597595  [    0/60000]\n",
            "loss: 0.690130  [ 6400/60000]\n",
            "loss: 0.472844  [12800/60000]\n",
            "loss: 0.709356  [19200/60000]\n",
            "loss: 0.628275  [25600/60000]\n",
            "loss: 0.610563  [32000/60000]\n",
            "loss: 0.660586  [38400/60000]\n",
            "loss: 0.695333  [44800/60000]\n",
            "loss: 0.683195  [51200/60000]\n",
            "loss: 0.642328  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 77.9%, Avg loss: 0.636227 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 0.582102  [    0/60000]\n",
            "loss: 0.674998  [ 6400/60000]\n",
            "loss: 0.460434  [12800/60000]\n",
            "loss: 0.698409  [19200/60000]\n",
            "loss: 0.619902  [25600/60000]\n",
            "loss: 0.602153  [32000/60000]\n",
            "loss: 0.646996  [38400/60000]\n",
            "loss: 0.687480  [44800/60000]\n",
            "loss: 0.675039  [51200/60000]\n",
            "loss: 0.631391  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 78.2%, Avg loss: 0.625282 \n",
            "\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "epochs = 5\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train(train_dataloader, model, loss_fn, optimizer)\n",
        "    test(test_dataloader, model, loss_fn)\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Read more about `Training your model <optimization_tutorial.html>`_.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "--------------\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Saving Models\n",
        "-------------\n",
        "A common way to save a model is to serialize the internal state dictionary (containing the model parameters).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved PyTorch Model State to model.pth\n"
          ]
        }
      ],
      "source": [
        "torch.save(model.state_dict(), \"model.pth\")\n",
        "print(\"Saved PyTorch Model State to model.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Loading Models\n",
        "----------------------------\n",
        "\n",
        "The process for loading a model includes re-creating the model structure and loading\n",
        "the state dictionary into it.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = NeuralNetwork()\n",
        "model.load_state_dict(torch.load(\"model.pth\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This model can now be used to make predictions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted: \"Ankle boot\", Actual: \"Ankle boot\"\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "⁡⁢⁣⁢IMPORTANTE⁡\n",
        "No podes ejecutar este codigo saltandote la parte de ⁡⁣⁣⁢re instanciar el modelo⁡, ya que el modelo de entrenamiento\n",
        "podra estar usando GPU, y aca hacemos una prediccion de un escalar, que ⁡⁣⁣⁢no esta en GPU.⁡\n",
        "para usarlo con GPU tendrias que convertir el escalar en un tensor y moverlo a GPU, y todo ese tiempo perdido \n",
        "para evaluar una sola prediccion es un desperdicio de tiempo.\n",
        "\"\"\"\n",
        "\n",
        "classes = [\n",
        "    \"T-shirt/top\",\n",
        "    \"Trouser\",\n",
        "    \"Pullover\",\n",
        "    \"Dress\",\n",
        "    \"Coat\",\n",
        "    \"Sandal\",\n",
        "    \"Shirt\",\n",
        "    \"Sneaker\",\n",
        "    \"Bag\",\n",
        "    \"Ankle boot\",\n",
        "]\n",
        "\n",
        "model.eval()\n",
        "x, y = test_data[0][0], test_data[0][1]\n",
        "with torch.no_grad():\n",
        "    pred = model(x)\n",
        "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
        "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Read more about `Saving & Loading your model <saveloadrun_tutorial.html>`_.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted: \"Ankle boot\", Actual: \"Ankle boot\"\n",
            "-----------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                         Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  \n",
            "-----------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                  aten::zeros         2.72%      15.000us         8.89%      49.000us      49.000us           4 b           0 b             1  \n",
            "                  aten::empty         5.99%      33.000us         5.99%      33.000us      16.500us         268 b         268 b             2  \n",
            "                  aten::zero_         0.36%       2.000us         0.36%       2.000us       2.000us           0 b           0 b             1  \n",
            "              model_inference        25.59%     141.000us        91.11%     502.000us     502.000us          -4 b      -8.31 Kb             1  \n",
            "                aten::flatten         0.73%       4.000us         1.45%       8.000us       8.000us           0 b           0 b             1  \n",
            "         aten::_reshape_alias         0.73%       4.000us         0.73%       4.000us       4.000us           0 b           0 b             1  \n",
            "                 aten::linear         1.63%       9.000us        58.44%     322.000us     107.333us       4.04 Kb           0 b             3  \n",
            "                      aten::t         0.91%       5.000us         2.36%      13.000us       4.333us           0 b           0 b             3  \n",
            "              aten::transpose         0.73%       4.000us         1.45%       8.000us       2.667us           0 b           0 b             3  \n",
            "             aten::as_strided         1.09%       6.000us         1.09%       6.000us       0.750us           0 b           0 b             8  \n",
            "                  aten::addmm        52.45%     289.000us        54.45%     300.000us     100.000us       4.04 Kb       4.00 Kb             3  \n",
            "                 aten::expand         0.73%       4.000us         0.91%       5.000us       1.667us          40 b          40 b             3  \n",
            "                  aten::copy_         0.91%       5.000us         0.91%       5.000us       1.667us           0 b           0 b             3  \n",
            "           aten::resolve_conj         0.18%       1.000us         0.18%       1.000us       0.167us           0 b           0 b             6  \n",
            "                   aten::relu         1.09%       6.000us         2.54%      14.000us       7.000us       4.00 Kb           0 b             2  \n",
            "              aten::clamp_min         1.45%       8.000us         1.45%       8.000us       4.000us       4.00 Kb       4.00 Kb             2  \n",
            "                 aten::select         0.18%       1.000us         0.36%       2.000us       2.000us           0 b           0 b             1  \n",
            "                 aten::argmax         2.18%      12.000us         2.18%      12.000us      12.000us           8 b           8 b             1  \n",
            "                   aten::item         0.18%       1.000us         0.36%       2.000us       2.000us           0 b           0 b             1  \n",
            "    aten::_local_scalar_dense         0.18%       1.000us         0.18%       1.000us       1.000us           0 b           0 b             1  \n",
            "-----------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 551.000us\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from torch.profiler import profile, record_function, ProfilerActivity\n",
        "\n",
        "# Ver el rendimiento en cpu\n",
        "\n",
        "model.eval()\n",
        "x, y = test_data[0][0], test_data[0][1]\n",
        "\n",
        "with profile(activities=[ProfilerActivity.CPU],profile_memory=True, record_shapes=True) as prof:\n",
        "    with record_function(\"model_inference\"):\n",
        "        with torch.no_grad():\n",
        "            pred = model(x)\n",
        "            predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
        "            print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')\n",
        "\n",
        "print(prof.key_averages().table())\n",
        "# exportar y se puede ver yendo a chrome en la URL chrome://tracing\n",
        "prof.export_chrome_trace(\"trace.json\")\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "9abe774f74fe6e9a34c044080c00539c2573e8d4e4c28ec478136b0c7aa9cb53"
    },
    "kernelspec": {
      "display_name": "Python 3.9.12 ('tesis')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
